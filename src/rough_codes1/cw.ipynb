{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf=int(input('how many files to compare?'))\n",
    "\n",
    "strg=[]\n",
    "for i in range (nf):\n",
    "    filename = input('Enter a filename: ')\n",
    "    with open('input/'+filename, 'r') as file:\n",
    "        data = file.read()\n",
    "    str1=\" \".join(data.split())\n",
    "    nlp = spacy.load(\"en_core_web_lg\")\n",
    "    str2=''\n",
    "    doc = nlp(str1)\n",
    "    for token in doc:\n",
    "        str2=str2+\" \"+token.lemma_\n",
    "    str2=\" \".join(str2.split())\n",
    "    doc1 = nlp(str2)\n",
    "    words = [token.text for token in doc1 if token.is_stop != True and token.is_punct != True]\n",
    "    str3=''\n",
    "    str3=\" \".join(words)\n",
    "    strg.append(str3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "words of text  1  are  ['able', 'accomplishment', 'adapt', 'additionally', 'adjust', 'attitude', 'basis', 'benefit', 'broaden', 'challenge', 'challenging', 'change', 'come', 'comfort', 'communication', 'concern', 'cost', 'country', 'culture', 'custom', 'daily', 'deal', 'despite', 'develop', 'development', 'different', 'difficult', 'distance', 'drawback', 'enhance', 'enriching', 'environment', 'especially', 'expense', 'experience', 'expose', 'family', 'far', 'fluency', 'force', 'foreign', 'friend', 'furthermore', 'gain', 'global', 'greatly', 'help', 'high', 'home', 'homesickness', 'immerse', 'improve', 'incredibly', 'independence', 'individual', 'initial', 'invaluable', 'language', 'learn', 'learning', 'life', 'lifetime', 'live', 'living', 'maintain', 'major', 'memory', 'minded', 'native', 'navigate', 'new', 'oneself', 'open', 'opportunity', 'outweigh', 'overall', 'overseas', 'personal', 'perspective', 'pride', 'problem', 'professional', 'provide', 'relationship', 'reliance', 'require', 'rewarding', 'self', 'sense', 'set', 'skill', 'solve', 'speaker', 'stage', 'step', 'study', 'surround', 'system', 'thrive', 'time', 'tolerant', 'truly', 'understanding', 'unfamiliar', 'unique', 'valuable', 'value', 'way', 'world', 'zone'] 110\n",
      "\n",
      "words of text  2  are  ['activity', 'addition', 'additionally', 'anxiety', 'benefit', 'bond', 'bone', 'boost', 'cancer', 'cardiovascular', 'chemical', 'chronic', 'cognitive', 'cold', 'compelling', 'component', 'conclusion', 'confidence', 'countless', 'create', 'cycling', 'depression', 'diabetes', 'discuss', 'disease', 'endorphin', 'energy', 'enjoy', 'essay', 'essential', 'esteem', 'exercise', 'experience', 'family', 'feel', 'fitness', 'foremost', 'friend', 'fulfil', 'fun', 'function', 'furthermore', 'good', 'health', 'healthy', 'heart', 'help', 'illness', 'immune', 'impact', 'improve', 'include', 'know', 'lead', 'life', 'lifestyle', 'lower', 'maintain', 'memory', 'mental', 'mood', 'muscle', 'offer', 'opportunity', 'overall', 'perfect', 'physical', 'play', 'positive', 'provide', 'quality', 'reason', 'reduce', 'regular', 'release', 'risk', 'routine', 'run', 'self', 'sense', 'sleep', 'social', 'sport', 'strengthen', 'stress', 'susceptible', 'swimming', 'system', 'vital', 'weight'] 90\n",
      "\n",
      "there are  17  common words between text  1  and  2  and they are: \n",
      " ['additionally', 'benefit', 'experience', 'family', 'friend', 'furthermore', 'help', 'improve', 'life', 'maintain', 'memory', 'opportunity', 'overall', 'provide', 'self', 'sense', 'system']\n",
      "\n",
      "words of text  3  are  ['Facebook', 'Twitter', 'able', 'adapt', 'additionally', 'advertising', 'age', 'availability', 'big', 'break', 'cause', 'century', 'certainly', 'citizen', 'comprehensive', 'conclusion', 'continue', 'convenience', 'coverage', 'decline', 'decrease', 'depth', 'detailed', 'difficult', 'digital', 'enjoy', 'event', 'experience', 'fact', 'factor', 'financially', 'find', 'format', 'future', 'generate', 'hard', 'impact', 'important', 'increasingly', 'industry', 'information', 'internet', 'investigative', 'issue', 'journalism', 'lead', 'masse', 'medium', 'modern', 'news', 'newspaper', 'number', 'online', 'past', 'people', 'physical', 'platform', 'play', 'prefer', 'print', 'provide', 'question', 'quick', 'read', 'reader', 'reason', 'recent', 'replace', 'revenue', 'rise', 'role', 'shift', 'smartphone', 'social', 'society', 'source', 'staple', 'subscription', 'successfully', 'survive', 'tactile', 'tell', 'thing', 'thrive', 'time', 'traditional', 'transition', 'turn', 'ultimately', 'uncertain', 'update', 'vital', 'way', 'widespread', 'year'] 95\n",
      "\n",
      "there are  12  common words between text  2  and  3  and they are: \n",
      " ['additionally', 'conclusion', 'enjoy', 'experience', 'impact', 'lead', 'physical', 'play', 'provide', 'reason', 'social', 'vital']\n",
      "\n",
      "words of text  4  are  ['access', 'additionally', 'address', 'advancement', 'aid', 'artificial', 'aspect', 'attitude', 'automation', 'belief', 'change', 'collaboration', 'combination', 'communication', 'compassion', 'conclusion', 'convenient', 'cultural', 'deeply', 'despite', 'digital', 'discrimination', 'disparity', 'displacement', 'divide', 'easy', 'economic', 'effort', 'empathy', 'entertainment', 'exacerbate', 'example', 'exist', 'existence', 'field', 'furthermore', 'gap', 'greatly', 'homelessness', 'human', 'hunger', 'important', 'improve', 'inability', 'industry', 'inequality', 'ingrained', 'integral', 'intelligence', 'issue', 'job', 'labor', 'lead', 'life', 'limitation', 'main', 'medicine', 'need', 'poverty', 'problem', 'provide', 'racism', 'recognize', 'refer', 'replace', 'require', 'role', 'root', 'significant', 'social', 'societal', 'socio', 'solely', 'solution', 'solve', 'stride', 'technical', 'technological', 'technology', 'tool', 'touch', 'transportation', 'world'] 83\n",
      "\n",
      "there are  11  common words between text  3  and  4  and they are: \n",
      " ['additionally', 'conclusion', 'digital', 'important', 'industry', 'issue', 'lead', 'provide', 'replace', 'role', 'social']\n",
      "\n",
      "words of text  5  are  ['100', '9', 'Cannabis', 'Egyptians', 'Indians', 'States', 'THC', 'United', 'abuse', 'accept', 'access', 'addiction', 'affect', 'ailment', 'ancient', 'associate', 'believe', 'benefit', 'cancer', 'cannabi', 'cannabidiol', 'cannabinoid', 'cannabis', 'cause', 'cbd', 'century', 'certain', 'chemical', 'chemotherapy', 'chinese', 'chronic', 'classification', 'cognitive', 'commonly', 'compound', 'conclusion', 'condition', 'consider', 'contain', 'control', 'currently', 'derive', 'despite', 'different', 'difficult', 'disorder', 'drug', 'easy', 'effect', 'effective', 'estimate', 'function', 'grow', 'health', 'hemp', 'high', 'history', 'include', 'increase', 'know', 'lead', 'legalize', 'long', 'marijuana', 'mean', 'medical', 'medicinal', 'mental', 'movement', 'multiple', 'nausea', 'negative', 'pain', 'patient', 'plant', 'post', 'potential', 'problem', 'produce', 'property', 'psychoactive', 'purpose', 'recent', 'recreational', 'remain', 'research', 'researcher', 'respiratory', 'responsible', 'risk', 'sativa', 'schedule', 'sclerosis', 'state', 'stress', 'study', 'substance', 'tetrahydrocannabinol', 'thousand', 'time', 'traumatic', 'treat', 'treatment', 'type', 'use', 'user', 'variety', 'vomiting', 'year'] 109\n",
      "\n",
      "there are  6  common words between text  4  and  5  and they are: \n",
      " ['access', 'conclusion', 'despite', 'easy', 'lead', 'problem']\n"
     ]
    }
   ],
   "source": [
    "for j in range(len(strg)):\n",
    "    #print(\"string \",j,\" is \\n\",strg[j])\n",
    "    if j==0:\n",
    "        str1=strg[j]\n",
    "        words1 = set(str1.split())\n",
    "        print(\"\\nwords of text \",j+1,\" are \",sorted(words1),len(words1))\n",
    "        continue\n",
    "    str1=strg[j]\n",
    "    words2 = set(str1.split())\n",
    "    print(\"\\nwords of text \",j+1,\" are \",sorted(words2),len(words2))\n",
    "    common_words = words1.intersection(words2)\n",
    "    print(\"\\nthere are \",len(common_words),\" common words between text \",j,\" and \",j+1,\" and they are: \\n\",sorted(common_words))\n",
    "    words1 = words2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\n"
     ]
    }
   ],
   "source": [
    "print(len(common_words))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Human generated essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf1=int(input('how many files to compare?'))\n",
    "\n",
    "strg1=[]\n",
    "for i in range (nf1):\n",
    "    filename = input('Enter a filename: ')\n",
    "    with open('human/'+filename, 'r') as file:\n",
    "        data1 = file.read()\n",
    "    str4=\" \".join(data1.split())\n",
    "    nlp = spacy.load(\"en_core_web_lg\")\n",
    "    str5=''\n",
    "    doc2 = nlp(str4)\n",
    "    for token in doc2:\n",
    "        str5=str5+\" \"+token.lemma_\n",
    "    str5=\" \".join(str5.split())\n",
    "    doc3 = nlp(str5)\n",
    "    words = [token.text for token in doc3 if token.is_stop != True and token.is_punct != True]\n",
    "    str6=''\n",
    "    str6=\" \".join(words)\n",
    "    strg1.append(str6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "words of text  1  are  ['achieve', 'adapt', 'away', 'come', 'communicate', 'compare', 'conclusion', 'country', 'course', 'culture', 'depend', 'desire', 'different', 'difficulty', 'edge', 'eligible', 'employer', 'environment', 'experience', 'face', 'family', 'follow', 'foot', 'friend', 'gain', 'general', 'good', 'home', 'improve', 'individual', 'interact', 'international', 'irreplaceable', 'job', 'language', 'learn', 'life', 'likely', 'live', 'loneliness', 'look', 'market', 'new', 'opinion', 'opportunity', 'origin', 'overseas', 'peer', 'people', 'perspective', 'prefer', 'reason', 'second', 'situation', 'skill', 'social', 'stand', 'step', 'struggle', 'student', 'study', 'subject', 'successful', 'turn', 'university', 'valuable'] 66\n",
      "\n",
      "words of text  2  are  ['1.6', '2', 'America', 'Americans', 'States', 'United', 'able', 'achieve', 'active', 'activity', 'actually', 'air', 'american', 'annually', 'anxiety', 'appearance', 'appreciate', 'beneficial', 'benefit', 'billion', 'body', 'brain', 'bring', 'cancer', 'cause', 'certain', 'chemical', 'come', 'common', 'concerned', 'conclusion', 'condition', 'confidence', 'consistent', 'control', 'create', 'day', 'death', 'decide', 'depression', 'diabetes', 'different', 'disease', 'easily', 'eat', 'effect', 'endorphin', 'energy', 'enjoy', 'enjoyable', 'enormous', 'esteem', 'everyday', 'evidence', 'excerise', 'excuse', 'exercise', 'exercising', 'experience', 'extra', 'extremely', 'fast', 'fat', 'feel', 'feeling', 'figure', 'find', 'food', 'form', 'forward', 'fun', 'function', 'goal', 'good', 'great', 'happy', 'hard', 'health', 'healthy', 'heart', 'help', 'helps', 'high', 'illness', 'important', 'improve', 'key', 'killer', 'life', 'likely', 'live', 'long', 'look', 'lose', 'lot', 'low', 'lung', 'main', 'matter', 'memory', 'mental', 'motivated', 'muscle', 'number', 'numerous', 'obese', 'obesity', 'opinion', 'outlook', 'overall', 'overweight', 'oxygen', 'people', 'percent', 'physical', 'plenty', 'plus', 'positive', 'prevent', 'problem', 'prove', 'rate', 'realize', 'reason', 'reduce', 'release', 'relieve', 'require', 'result', 'reward', 'rewarding', 'risk', 'second', 'self', 'set', 'society', 'sport', 'stay', 'stress', 'stroke', 'strong', 'study', 'suffer', 'tension', 'thing', 'think', 'time', 'today', 'truly', 'try', 'type', 'want', 'way', 'weight', 'work', 'world', 'worth', 'worthwhile'] 158\n",
      "\n",
      "there are  16  common words between text  1  and  2  and they are: \n",
      " ['achieve', 'come', 'conclusion', 'different', 'experience', 'good', 'improve', 'life', 'likely', 'live', 'look', 'opinion', 'people', 'reason', 'second', 'study']\n",
      "\n",
      "words of text  3  are  ['acquire', 'advantage', 'advocate', 'agree', 'alive', 'answer', 'anytime', 'appear', 'argue', 'arise', 'aspect', 'available', 'believe', 'buy', 'clear', 'close', 'come', 'common', 'competitive', 'computer', 'conceive', 'conclusion', 'connect', 'consideration', 'continue', 'contrary', 'contributor', 'convenient', 'cost', 'country', 'cut', 'daily', 'decline', 'deforestation', 'device', 'disagree', 'dramatic', 'easy', 'economic', 'environment', 'environmentalist', 'ever-', 'exist', 'existence', 'experience', 'extinction', 'extra', 'face', 'fail', 'fall', 'follow', 'free', 'happen', 'hardly', 'hour', 'huge', 'important', 'inclined', 'increase', 'information', 'innovation', 'internet', 'late', 'lead', 'life', 'long', 'lose', 'low', 'machine', 'medium', 'mobile', 'modern', 'money', 'news', 'newspaper', 'nowadays', 'number', 'obtain', 'occur', 'page', 'past', 'people', 'person', 'personally', 'phone', 'point', 'popular', 'possibly', 'print', 'production', 'prolonged', 'provide', 'provision', 'publish', 'question', 'quick', 'rational', 'read', 'reader', 'reason', 'receive', 'recent', 'recognize', 'result', 'role', 'second', 'service', 'sharply', 'simply', 'source', 'spend', 'sustain', 'technology', 'thing', 'time', 'today', 'tree', 'type', 'unpleasant', 'update', 'use', 'usually', 'view', 'wait', 'waste', 'way', 'witness', 'world', 'year'] 129\n",
      "\n",
      "there are  21  common words between text  2  and  3  and they are: \n",
      " ['come', 'common', 'conclusion', 'experience', 'extra', 'important', 'life', 'long', 'lose', 'low', 'number', 'people', 'reason', 'result', 'second', 'thing', 'time', 'today', 'type', 'way', 'world']\n",
      "\n",
      "words of text  4  are  ['ability', 'abuse', 'access', 'accordingly', 'accurately', 'addition', 'advance', 'advantage', 'aspect', 'attack', 'attention', 'bear', 'begin', 'believe', 'blood', 'clearly', 'computer', 'conclusion', 'contribute', 'crucial', 'cure', 'damage', 'dangerous', 'deadly', 'death', 'detrimental', 'develop', 'development', 'device', 'disadvantage', 'disagree', 'disaster', 'disease', 'dispute', 'drawback', 'easy', 'economy', 'education', 'effect', 'efficiently', 'emphasis', 'enable', 'fact', 'fast', 'fatal', 'feel', 'good', 'greatly', 'hardly', 'health', 'heart', 'help', 'hi', 'high', 'huge', 'impact', 'improve', 'improvement', 'include', 'information', 'instead', 'integral', 'internet', 'intricate', 'invention', 'kind', 'lead', 'life', 'likely', 'live', 'lot', 'medical', 'mind', 'modern', 'natural', 'need', 'negative', 'new', 'nowadays', 'number', 'obesity', 'outweigh', 'partly', 'pay', 'peace', 'people', 'personally', 'place', 'play', 'point', 'politic', 'positive', 'powerful', 'predict', 'pressure', 'problem', 'property', 'reason', 'recognition', 'reduce', 'result', 'science', 'scientist', 'second', 'severely', 'solution', 'spend', 'spring', 'standard', 'strongly', 'study', 'tech', 'technological', 'technology', 'threat', 'time', 'try', 'use', 'value', 'view', 'weapon', 'work', 'world'] 123\n",
      "\n",
      "there are  29  common words between text  3  and  4  and they are: \n",
      " ['advantage', 'aspect', 'believe', 'computer', 'conclusion', 'device', 'disagree', 'easy', 'hardly', 'huge', 'information', 'internet', 'lead', 'life', 'modern', 'nowadays', 'number', 'people', 'personally', 'point', 'reason', 'result', 'second', 'spend', 'technology', 'time', 'use', 'view', 'world']\n",
      "\n",
      "words of text  5  are  ['$', '16trillion', '25', '5', '79,000', 'Cannabis', 'Marijuana', 'People', 'Prison', 'States', 'Statistics', 'United', 'abuse', 'accurate', 'adapt', 'addictive', 'admit', 'alcohol', 'appetite', 'argue', 'army', 'belief', 'believe', 'benefit', 'black', 'body', 'cancer', 'cannabis', 'cartel', 'cashier', 'check', 'child', 'classify', 'cocaine', 'company', 'complete', 'concept', 'country', 'create', 'creative', 'crime', 'criminal', 'cut', 'd', 'dangerous', 'deal', 'dealer', 'debt', 'despite', 'die', 'dollar', 'drug', 'earth', 'easy', 'economy', 'effect', 'effort', 'example', 'expect', 'explain', 'expose', 'extremely', 'failure', 'federal', 'fill', 'food', 'gateway', 'government', 'great', 'greatly', 'group', 'hand', 'hardcore', 'harmful', 'harsh', 'hear', 'help', 'heroin', 'hold', 'huge', 'idea', 'illegal', 'imagine', 'information', 'introduce', 'job', 'kid', 'large', 'legal', 'legalization', 'legalize', 'like', 'lobby', 'lobbyist', 'lot', 'low', 'main', 'marijuana', 'market', 'medical', 'medication', 'mentally', 'mention', 'meth', 'mind', 'minded', 'money', 'moral', 'music', 'musician', 'narrow', 'national', 'nausea', 'new', 'non', 'obtain', 'open', 'oppose', 'overdose', 'painkiller', 'patient', 'pay', 'payer', 'people', 'percent', 'pharmaceutical', 'physically', 'point', 'poisoning', 'political', 'population', 'positive', 'pot', 'potential', 'power', 'price', 'prison', 'prisoner', 'profit', 'prohibition', 'purpose', 'reason', 'recreational', 'relate', 'release', 'remain', 'replace', 'save', 'schedule', 'significant', 'simple', 'sleep', 'society', 'start', 'statement', 'stimulate', 'strength', 'substance', 'suggest', 'susceptible', 'tax', 'teen', 'tell', 'thing', 'think', 'tobacco', 'ton', 'treatment', 'try', 'underground', 'unfair', 'unhealthy', 'use', 'violent', 'war', 'waste', 'way', 'world', 'year', 'zero'] 180\n",
      "\n",
      "there are  22  common words between text  4  and  5  and they are: \n",
      " ['abuse', 'believe', 'dangerous', 'easy', 'economy', 'effect', 'greatly', 'help', 'huge', 'information', 'lot', 'medical', 'mind', 'new', 'pay', 'people', 'point', 'positive', 'reason', 'try', 'use', 'world']\n"
     ]
    }
   ],
   "source": [
    "for j in range(len(strg1)):\n",
    "    #print(\"string \",j,\" is \\n\",strg1[j])\n",
    "    if j==0:\n",
    "        str7=strg1[j]\n",
    "        words1 = set(str7.split())\n",
    "        print(\"\\nwords of text \",j+1,\" are \",sorted(words1),len(words1))\n",
    "        continue\n",
    "    str7=strg1[j]\n",
    "    words2 = set(str7.split())\n",
    "    print(\"\\nwords of text \",j+1,\" are \",sorted(words2),len(words2))\n",
    "    common_words = words1.intersection(words2)\n",
    "    print(\"\\nthere are \",len(common_words),\" common words between text \",j,\" and \",j+1,\" and they are: \\n\",sorted(common_words))\n",
    "    words1 = words2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "266e07f64aa3f1afd9991a0b824d04fa241a0ccb3b0a1eb69e96cbe416527717"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
