{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "import nltk\n",
    "import re \n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "import statistics\n",
    "\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "import collections\n",
    "from collections import Counter\n",
    "import language_tool_python  \n",
    "from nltk.tokenize import sent_tokenize\n",
    "import textstat\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import math\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import language_tool_python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../csv/combined_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the DataFrame based on the 'label' column\n",
    "df1 = df[df['label'] == 1]\n",
    "df2 = df[df['label'] == 0]\n",
    "\n",
    "# Display the resulting DataFrames\n",
    "print(\"DataFrame 1 (label=1):\")\n",
    "print(df1)\n",
    "\n",
    "print(\"\\nDataFrame 2 (label=0):\")\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_2= pd.DataFrame(df2)\n",
    "df_2= pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2=df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df_2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grammar_check(text):\n",
    "    tool_gb = language_tool_python.LanguageTool('en-GB')\n",
    "\n",
    "    substr1 = \"is American English\"\n",
    "    substr2 = \"British English\"\n",
    "    substr3 = \"Consider shortening\"\n",
    "    \n",
    "    matches = tool_gb.check(text)\n",
    "    cnt=0\n",
    "    for match in matches:\n",
    "        if substr1 in match.message or substr2 in match.message or substr3 in match.message:\n",
    "            #print(\"***********this the US case/case to ignore****************\")\n",
    "            #print(match.message)\n",
    "            continue\n",
    "        \n",
    "        else:\n",
    "            cnt+=1\n",
    "            print(\"***********this other cases****************\")\n",
    "            print(match)\n",
    "            \n",
    "    print(\"total count \",cnt)\n",
    "    return(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ess1=df1.loc[:,'essay']\n",
    "ess2=new_df.loc[:,'essay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ess2)):\n",
    "    err_count=grammar_check(ess2[i])\n",
    "    print(\"number of error for \",i,\"th essay \",err_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
