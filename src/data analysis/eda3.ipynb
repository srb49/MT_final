{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import normalize\n",
    "import spacy\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('../../csv/gpt/csv_gpt3-2.csv')\n",
    "df2 = pd.read_csv('../../csv/human/csv_human-2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('../csv/cfinal2.csv', index=False)\n",
    "df2.to_csv('../csv/cfinal2.csv',mode='a',header=None,index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=pd.read_csv('../../csv/cfinal2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove unique as it is similar to lexical\n",
    "### remove number number_of_repeatation, max_occurance_of_most_frequent_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all columns of the DataFrame\n",
    "columns_list = df3.columns\n",
    "\n",
    "# Display the list of columns\n",
    "print(\"Columns of the DataFrame:\")\n",
    "print(columns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df3['unique_words_rates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df3['number_of_repeatation']\n",
    "del df3['max_occurance_of_most_frequent_phrase']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### introducing stop words rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_w_r(str1):\n",
    "    nw = word_tokenize(str1)\n",
    "    n=len(nw)\n",
    "\n",
    "    nlp = spacy.load(\"en_core_web_lg\")\n",
    "    text = nlp(str1)\n",
    "    words = [token.text for token in text if token.is_stop == True]\n",
    "    #print(words)\n",
    "    \n",
    "\n",
    "    l=len(words)\n",
    "    #print(\"n and l \",n,l)\n",
    "    swr=l/n\n",
    "    return swr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ess=df3.loc[:,'essay']\n",
    "sw_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ess)):\n",
    "    swr=stop_w_r(ess[i])\n",
    "    #print(swr)\n",
    "    sw_list.append(swr)\n",
    "    df3.at[i,'sw_rate']=swr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.insert(len(df3.columns) - 1, 'sw_rate', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns of the DataFrame:\n",
      "Index(['essay', 'topic', 'para_count', 'word_count', 'sentence_count',\n",
      "       'sentence_len(mean)', 'sentence_len(max)', 'sentence_len(min)',\n",
      "       'sw_rates', 'unique_words', 'noun', 'verb', 'adj', 'pron', 'modal verb',\n",
      "       'occurrance_of_most_freq_word', 'rate_of_occurrance',\n",
      "       'avg sentence complexity', 'lexical diversity', 'word_sim_p_count',\n",
      "       'word_sim_p_score', 'word_sim_n_count', 'word_sim_n_score',\n",
      "       'word_sim_score', 'flesch grade', 'Automated Readability',\n",
      "       'coleman_liau', 'cohesion score', 'positive_sentiment',\n",
      "       'negative_sentiment', 'neutral_sentiment', 'discourse_marker',\n",
      "       'grammar', 'sw_rate', 'label'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "columns_list = df3.columns\n",
    "\n",
    "# Display the list of columns\n",
    "print(\"Columns of the DataFrame:\")\n",
    "print(columns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv('../csv/combined.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n-gram repetation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../csv/combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_names = ['sum_repeated_ngrams', 'count_repeated_ngrams', 'max_occurrence_ngrams']\n",
    "\n",
    "# Get the index of the last column\n",
    "last_column_index = df.columns.get_loc('label')\n",
    "\n",
    "# Add three new columns with specific names before the last column with no values\n",
    "for new_column_name in reversed(new_column_names):\n",
    "    df.insert(last_column_index, new_column_name, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns of the DataFrame:\n",
      "Index(['essay', 'topic', 'para_count', 'word_count', 'sentence_count',\n",
      "       'sentence_len(mean)', 'sentence_len(max)', 'sentence_len(min)',\n",
      "       'sw_rates', 'unique_words', 'noun', 'verb', 'adj', 'pron', 'modal verb',\n",
      "       'occurrance_of_most_freq_word', 'rate_of_occurrance',\n",
      "       'avg sentence complexity', 'lexical diversity', 'word_sim_p_count',\n",
      "       'word_sim_p_score', 'word_sim_n_count', 'word_sim_n_score',\n",
      "       'word_sim_score', 'flesch grade', 'Automated Readability',\n",
      "       'coleman_liau', 'cohesion score', 'positive_sentiment',\n",
      "       'negative_sentiment', 'neutral_sentiment', 'discourse_marker',\n",
      "       'grammar', 'sw_rate', 'sum_repeated_ngrams', 'count_repeated_ngrams',\n",
      "       'max_occurrence_ngrams', 'label'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "columns_list = df.columns\n",
    "\n",
    "# Display the list of columns\n",
    "print(\"Columns of the DataFrame:\")\n",
    "print(columns_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ngrams(s, n):\n",
    "    # Convert to lowercases\n",
    "    s = s.lower()\n",
    "    \n",
    "    # Replace all none alphanumeric characters with spaces\n",
    "    s = re.sub(r'[^a-zA-Z0-9\\s]', ' ', s)\n",
    "    \n",
    "    # Break sentence in the token, remove empty tokens\n",
    "    tokens = [token for token in s.split(\" \") if token != \"\"]\n",
    "    \n",
    "    # Use the zip function to help us generate n-grams\n",
    "    # Concatentate the tokens into ngrams and return\n",
    "    ngrams = zip(*[tokens[i:] for i in range(n)])\n",
    "    list1=[\" \".join(ngram) for ngram in ngrams]\n",
    "    #return [\" \".join(ngram) for ngram in ngrams]\n",
    "    return list1\n",
    "\n",
    "def rep_count(str1):\n",
    "    list1=generate_ngrams(str1, 5)\n",
    "    sentence_counter = Counter(list1)\n",
    "    #print(sentence_counter)\n",
    "    total_freq=0\n",
    "    total_rep=0\n",
    "    for sentence, frequency in sentence_counter.items():\n",
    "        if frequency > 1:\n",
    "            total_freq+=frequency\n",
    "            total_rep+=1\n",
    "            #print(f\"Sentence: '{sentence}' - Frequency: {frequency}\")\n",
    "    #print(\"number of sentences appeared more than once \",total_rep,\" and total number of frequency(that are>1) \",total_freq)\n",
    "    return total_freq,total_rep, sentence_counter.most_common(1)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ess=df.loc[:,'essay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ess)):\n",
    "    print(\"################################ for essay number \",i,\" ###############################################\")\n",
    "    tf1,tr1,max_rep1=rep_count(ess[i])\n",
    "    df.at[i,'sum_repeated_ngrams']=tf1\n",
    "    df.at[i,'count_repeated_ngrams']=tr1 \n",
    "    df.at[i,'max_occurrence_ngrams']=max_rep1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../csv/combined_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "renaming sw_rates to avg_sw : avg_sw is stopwords per sentence and sw_rate(which is another column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../csv/combined_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'sw_rates': 'avg_stop_word'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns of the DataFrame:\n",
      "Index(['essay', 'topic', 'para_count', 'word_count', 'sentence_count',\n",
      "       'sentence_len(mean)', 'sentence_len(max)', 'sentence_len(min)',\n",
      "       'avg_stop_word', 'unique_words', 'noun', 'verb', 'adj', 'pron',\n",
      "       'modal verb', 'occurrance_of_most_freq_word', 'rate_of_occurrance',\n",
      "       'avg sentence complexity', 'lexical diversity', 'word_sim_p_count',\n",
      "       'word_sim_p_score', 'word_sim_n_count', 'word_sim_n_score',\n",
      "       'word_sim_score', 'flesch grade', 'Automated Readability',\n",
      "       'coleman_liau', 'cohesion score', 'positive_sentiment',\n",
      "       'negative_sentiment', 'neutral_sentiment', 'discourse_marker',\n",
      "       'grammar', 'sw_rate', 'sum_repeated_ngrams', 'count_repeated_ngrams',\n",
      "       'max_occurrence_ngrams', 'label'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "columns_list = df.columns\n",
    "\n",
    "# Display the list of columns\n",
    "print(\"Columns of the DataFrame:\")\n",
    "print(columns_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "#get correlations of each features in dataset\n",
    "corrmat = df.corr()\n",
    "top_corr_features = corrmat.index\n",
    "plt.figure(figsize=(20,20))\n",
    "#plot heat map\n",
    "g=sns.heatmap(df[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the combined dataframe to human and chatgpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the DataFrame based on the 'label' column\n",
    "df1 = df[df['label'] == 1]\n",
    "df2 = df[df['label'] == 0]\n",
    "\n",
    "# Display the resulting DataFrames\n",
    "print(\"DataFrame 1 (label=1):\")\n",
    "print(df1)\n",
    "\n",
    "print(\"\\nDataFrame 2 (label=0):\")\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the DataFrames\n",
    "combined_data = pd.concat([df1, df2])\n",
    "\n",
    "# Create a pairplot with different colors for each DataFrame\n",
    "sns.pairplot(combined_data, hue='label', markers=[\"o\", \"s\"], palette={0: \"b\", 1: \"r\"})\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../csv/combined_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../csv/combined_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns to plot\n",
    "x1 = df1[\"pron\"]\n",
    "y1 = df1[\"sw_rate\"]\n",
    "\n",
    "x2 = df2[\"pron\"]\n",
    "y2 = df2[\"sw_rate\"]\n",
    "\n",
    "\n",
    "\n",
    "# Plot the scatter plot for the first dataframe\n",
    "plt.scatter(x1, y1, label=\"GPT\", marker=\"o\", c='skyblue',alpha=0.5)\n",
    "\n",
    "# Plot the scatter plot for the second dataframe\n",
    "plt.scatter(x2, y2, label=\"Human\", marker=\"x\",c='red', alpha=0.3)\n",
    "\n",
    "# Add labels and a legend\n",
    "plt.xlabel(\"pronun\")\n",
    "plt.ylabel(\"rate of stop words\")\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.title(\"Scatter Plot Comparison\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns to plot\n",
    "x1 = df1[\"coleman_liau\"]\n",
    "y1 = df1[\"sw_rate\"]\n",
    "\n",
    "x2 = df2[\"coleman_liau\"]\n",
    "y2 = df2[\"sw_rate\"]\n",
    "\n",
    "\n",
    "\n",
    "# Plot the scatter plot for the first dataframe\n",
    "plt.scatter(x1, y1, label=\"GPT\", marker=\"o\", c='skyblue',alpha=0.5)\n",
    "\n",
    "# Plot the scatter plot for the second dataframe\n",
    "plt.scatter(x2, y2, label=\"Human\", marker=\"x\",c='red', alpha=0.3)\n",
    "\n",
    "# Add labels and a legend\n",
    "plt.xlabel(\"coleman_liau\")\n",
    "plt.ylabel(\"rate of stop words\")\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.title(\"Scatter Plot Comparison\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns to plot\n",
    "x1 = df1[\"lexical diversity\"]\n",
    "y1 = df1[\"sw_rate\"]\n",
    "\n",
    "x2 = df2[\"lexical diversity\"]\n",
    "y2 = df2[\"sw_rate\"]\n",
    "\n",
    "\n",
    "\n",
    "# Plot the scatter plot for the first dataframe\n",
    "plt.scatter(x1, y1, label=\"GPT\", marker=\"o\", c='skyblue',alpha=0.5)\n",
    "\n",
    "# Plot the scatter plot for the second dataframe\n",
    "plt.scatter(x2, y2, label=\"Human\", marker=\"x\",c='red', alpha=0.3)\n",
    "\n",
    "# Add labels and a legend\n",
    "plt.xlabel(\"lexical diversity\")\n",
    "plt.ylabel(\"rate of stop words\")\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.title(\"Scatter Plot Comparison\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns to plot\n",
    "x1 = df1[\"noun\"]\n",
    "y1 = df1[\"sw_rate\"]\n",
    "\n",
    "x2 = df2[\"noun\"]\n",
    "y2 = df2[\"sw_rate\"]\n",
    "\n",
    "\n",
    "\n",
    "# Plot the scatter plot for the first dataframe\n",
    "plt.scatter(x1, y1, label=\"GPT\", marker=\"o\", c='skyblue',alpha=0.5)\n",
    "\n",
    "# Plot the scatter plot for the second dataframe\n",
    "plt.scatter(x2, y2, label=\"Human\", marker=\"x\",c='red', alpha=0.3)\n",
    "\n",
    "# Add labels and a legend\n",
    "plt.xlabel(\"rate of noun\")\n",
    "plt.ylabel(\"rate of stop words\")\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.title(\"Scatter Plot Comparison\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns to plot\n",
    "x1 = df1[\"avg_stop_word\"]\n",
    "y1 = df1[\"flesch grade\"]\n",
    "\n",
    "x2 = df2[\"avg_stop_word\"]\n",
    "y2 = df2[\"flesch grade\"]\n",
    "\n",
    "\n",
    "\n",
    "# Plot the scatter plot for the first dataframe\n",
    "plt.scatter(x1, y1, label=\"GPT\", marker=\"o\", c='skyblue',alpha=0.5)\n",
    "\n",
    "# Plot the scatter plot for the second dataframe\n",
    "plt.scatter(x2, y2, label=\"Human\", marker=\"x\",c='red', alpha=0.3)\n",
    "\n",
    "# Add labels and a legend\n",
    "plt.xlabel(\"avg sentence complexity\")\n",
    "plt.ylabel(\"flesch grade\")\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.title(\"Scatter Plot Comparison\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns to plot\n",
    "x1 = df2[\"avg sentence complexity\"]\n",
    "y1 = df2[\"flesch grade\"]\n",
    "# Plot the scatter plot for the first dataframe\n",
    "plt.scatter(x1, y1, label=\"GPT\", marker=\"o\", c='skyblue',alpha=0.5)\n",
    "\n",
    "# Add labels and a legend\n",
    "plt.xlabel(\"avg sentence complexity\")\n",
    "plt.ylabel(\"flesch grade\")\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.title(\"Scatter Plot Comparison\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns to plot\n",
    "x1 = df1[\"avg_stop_word\"]\n",
    "y1 = df1[\"Automated Readability\"]\n",
    "\n",
    "x2 = df2[\"avg_stop_word\"]\n",
    "y2 = df2[\"Automated Readability\"]\n",
    "\n",
    "\n",
    "\n",
    "# Plot the scatter plot for the first dataframe\n",
    "plt.scatter(x1, y1, label=\"GPT\", marker=\"o\", c='skyblue',alpha=0.5)\n",
    "\n",
    "# Plot the scatter plot for the second dataframe\n",
    "plt.scatter(x2, y2, label=\"Human\", marker=\"x\",c='red', alpha=0.3)\n",
    "\n",
    "# Add labels and a legend\n",
    "plt.xlabel(\"avg sentence complexity\")\n",
    "plt.ylabel(\"Automated Readability\")\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.title(\"Scatter Plot Comparison\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns to plot\n",
    "x1 = df1[\"avg sentence complexity\"]\n",
    "y1 = df1[\"count_repeated_ngrams\"]\n",
    "\n",
    "x2 = df2[\"avg sentence complexity\"]\n",
    "y2 = df2[\"count_repeated_ngrams\"]\n",
    "\n",
    "\n",
    "\n",
    "# Plot the scatter plot for the first dataframe\n",
    "plt.scatter(x1, y1, label=\"GPT\", marker=\"o\", c='skyblue',alpha=0.5)\n",
    "\n",
    "# Plot the scatter plot for the second dataframe\n",
    "plt.scatter(x2, y2, label=\"Human\", marker=\"x\",c='red', alpha=0.3)\n",
    "\n",
    "# Add labels and a legend\n",
    "plt.xlabel(\"average sentence complexity\")\n",
    "plt.ylabel(\"repetition of ngrams\")\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.title(\"Scatter Plot Comparison\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../../csv/combined_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns of the DataFrame:\n",
      "Index(['essay', 'topic', 'para_count', 'word_count', 'sentence_count',\n",
      "       'sentence_len(mean)', 'sentence_len(max)', 'sentence_len(min)',\n",
      "       'avg_stop_word', 'unique_words', 'noun', 'verb', 'adj', 'pron',\n",
      "       'modal verb', 'occurrance_of_most_freq_word', 'rate_of_occurrance',\n",
      "       'avg sentence complexity', 'lexical diversity', 'word_sim_p_count',\n",
      "       'word_sim_p_score', 'word_sim_n_count', 'word_sim_n_score',\n",
      "       'word_sim_score', 'flesch grade', 'Automated Readability',\n",
      "       'coleman_liau', 'positive_sentiment', 'negative_sentiment',\n",
      "       'neutral_sentiment', 'discourse_marker', 'grammar', 'sw_rate',\n",
      "       'sum_repeated_ngrams', 'count_repeated_ngrams', 'max_occurrence_ngrams',\n",
      "       'label'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "columns_list = df.columns\n",
    "print(\"Columns of the DataFrame:\")\n",
    "print(columns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['cohesion score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../../csv/combined_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "#get correlations of each features in dataset\n",
    "corrmat = df.corr()\n",
    "top_corr_features = corrmat.index\n",
    "plt.figure(figsize=(20,20))\n",
    "#plot heat map\n",
    "g=sns.heatmap(df[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_description = df1.describe(include='all')\n",
    "df1_description.to_csv('../xl/df1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_path = '../xl/df1.xlsx'\n",
    "df1_description.to_excel(excel_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_description = df2.describe(include='all')\n",
    "df2_description.to_csv('../xl/df2.csv', index=False)\n",
    "excel_path = '../xl/df2.xlsx'\n",
    "df2_description.to_excel(excel_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.describe(include='all').T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "es_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
